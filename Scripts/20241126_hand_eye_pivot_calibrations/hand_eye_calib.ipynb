{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import re \n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import importlib\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from data_processor import readCSVWStrArray\n",
    "from data_processor import IntrinsicCalib\n",
    "from data_processor import timeStampAligner\n",
    "from data_processor import videoToPng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_processor.timeStampAligner' from '/home/fj/Projects/ARPA-H/Scripts/20241126_hand_eye_pivot_calibrations/../../data_processor/timeStampAligner.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(timeStampAligner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 NDI files and 1 video timestamp files.\n",
      "Processing NDI file: /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/ndi_hand_eye_test_1.csv\n",
      "Processing video timestamp file: /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/hand_eye_test_2.csv\n",
      "(9381, 1, 4, 4)\n",
      "Aligned data saved to /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/ndi_hand_eye_test_1_aligned.csv\n",
      "Processing NDI file: /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/ndi_hand_eye_test_1_COPY.csv\n",
      "Processing video timestamp file: /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/hand_eye_test_2.csv\n",
      "(9381, 1, 4, 4)\n",
      "Aligned data saved to /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/ndi_hand_eye_test_1_COPY_aligned.csv\n",
      "Processing NDI file: /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/ndi_hand_eye_test_2.csv\n",
      "Processing video timestamp file: /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/hand_eye_test_2.csv\n",
      "(12681, 1, 4, 4)\n",
      "Aligned data saved to /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/ndi_hand_eye_test_2_aligned.csv\n",
      "Processing NDI file: /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/ndi_hand_eye_test_2_EMPTY.csv\n",
      "Processing video timestamp file: /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/hand_eye_test_2.csv\n",
      "(124, 1, 4, 4)\n",
      "Aligned data saved to /media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations/ndi_hand_eye_test_2_EMPTY_aligned.csv\n"
     ]
    }
   ],
   "source": [
    "## Clean/Align the tracking data\n",
    "basePath = pathlib.Path(\"/media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations\")\n",
    "timeStampAligner.processDirectory(basePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoBasePath = pathlib.Path(\"/media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations\")\n",
    "videoPath = videoBasePath / \"hand_eye_test_2.avi\"\n",
    "imageBasePath = pathlib.Path(\"/media/fj/Data/Projects/ARPA-H/data/20241126_hand_eye_pivot_calibrations//Recordings/run_2/cam0\")\n",
    "imagePath = imageBasePath / \"data\"\n",
    "timeStampsPath = videoBasePath / \"hand_eye_test_2.csv\"\n",
    "timeStamps = np.genfromtxt(timeStampsPath, delimiter=\",\", dtype=np.double)[:, 1]\n",
    "\n",
    "ndiDatapath = videoBasePath / \"ndi_hand_eye_test_2_aligned.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions of the checkerboard (number of inner corners per row and column)\n",
    "CHECKERBOARD_SHAPE = (10, 7)  # Adjust according to your checkerboard dimensions\n",
    "CHECKERBOARD_GRID_SIZE = 5 # mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10868, 1732652848813"
     ]
    }
   ],
   "source": [
    "videoToPng.saveFramesAsPng(videoPath, imagePath, timeStamps=timeStamps) # newSize=(640, 360), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Images: 10869\n",
      "9880/10869\n",
      "Error:\n",
      " 0.9313842907736611\n",
      "Camera Matrix:\n",
      " [[522.85179215   0.         680.9055524 ]\n",
      " [  0.         524.49884771 361.78848927]\n",
      " [  0.           0.           1.        ]]\n",
      "\n",
      "Distortion Coefficients:\n",
      " [[-0.38779207  0.20664283  0.00156769  0.00102807 -0.08947456]]\n"
     ]
    }
   ],
   "source": [
    "# Camera Calibration\n",
    "images = glob.glob(str(imagePath / \"*.png\"))\n",
    "print(f\"# of Images: {len(images)}\")\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "ret, camera_matrix, dist_coeffs, rvecs, tvecs, fileNames = IntrinsicCalib.detectCheckerboardAndIntrinsicCalib(images, CHECKERBOARD_SHAPE=CHECKERBOARD_SHAPE, CHECKERBOARD_GRID_SIZE=20, savePath=imageBasePath / \"intrinsics\", visualize=True, imageRange=[2500, len(images)-1000, 20], returnUsedFileNames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "usedTimeStamps = [int(f.split(\"/\")[-1][:-4]) for f in fileNames]\n",
    "R_target2cam = rvecs\n",
    "t_target2cam = tvecs\n",
    "\n",
    "ndiData = np.genfromtxt(ndiDatapath, delimiter=\",\") # [Translation, Quat]\n",
    "ndiDataTimeStamps = ndiData[:, 0].astype(int)\n",
    "\n",
    "usedNdiData = []\n",
    "for usedTimeStamp in usedTimeStamps:\n",
    "    idx = np.where(ndiDataTimeStamps == usedTimeStamp)[0][0]\n",
    "    usedNdiData.append(ndiData[idx, :])\n",
    "\n",
    "usedNdiData = np.array(usedNdiData)\n",
    "t_gripper2base = [usedNdiData[i, 1:4] for i in range(usedNdiData.shape[0])]\n",
    "R_gripper2base = [R.from_quat(usedNdiData[i, 4:]).as_matrix() for i in range(usedNdiData.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "handEyeR, handEyet = cv.calibrateHandEye(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand-Eye Calibration Result\n",
    "Using Method from [Tsai](https://ieeexplore.ieee.org/document/34770)\n",
    "Other OpenCV implemented methods are listed [here](https://docs.opencv.org/4.5.4/d9/d0c/group__calib3d.html#gad10a5ef12ee3499a0774c7904a801b99).\n",
    "\n",
    "Rotation and Translation\n",
    "```\n",
    "(array([[-0.05006572, -0.46495374,  0.88391823],\n",
    "        [ 0.01838049, -0.88530718, -0.46464326],\n",
    "        [ 0.99857678, -0.00701585,  0.05286962]]),\n",
    " array([[ 83.64166892],\n",
    "        [ 77.06542646],\n",
    "        [-21.23159487]]))\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.00657160e-02 -4.64953741e-01  8.83918233e-01  8.36416689e+01]\n",
      " [ 1.83804919e-02 -8.85307176e-01 -4.64643262e-01  7.70654265e+01]\n",
      " [ 9.98576778e-01 -7.01584563e-03  5.28696162e-02 -2.12315949e+01]]\n"
     ]
    }
   ],
   "source": [
    "handEyeT = np.concatenate((handEyeR, handEyet), axis=-1)\n",
    "print(handEyeT)\n",
    "handEyeT = np.concatenate((handEyeT, np.array([[0, 0, 0, 1]])), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./handEyeOutput.npy\", handEyeT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
